{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 15:41:26.447362: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 15:41:26.500394: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 15:41:26.503193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:41:26.503201: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-28 15:41:26.517199: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-28 15:41:26.795005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:41:26.795040: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:41:26.795043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')\n",
    "image_rows, image_columns, image_depth = 64, 64, 96\n",
    "look_frames = int(image_depth/2)\n",
    "num_classes = 3 # 分類類別 \n",
    "process_detect = False # 要不要對資料做 detect 處理\n",
    "version = True # F:舊版(39筆) 或 T:新版(269筆)\n",
    "\n",
    "\n",
    "training_list = []\n",
    "apexframe   = [[] for a in range(num_classes)] # 紀錄video的apex frame\n",
    "ifsamevideo = [[] for a in range(num_classes)] # 紀錄clip與其前一個clip是否來自相同video\n",
    "path = [[] for a in range(num_classes)]\n",
    "\n",
    "if version:\n",
    "    # anger\n",
    "    apexframe[0]   = [572,2163,3371,3757,569,1675,1758,421,1391,1881,2162,2912,3421,3943,3270,1898,3447,3309,3563,1139,1979,2168,\n",
    "                      2247,2641,3733,415,933,870,1694,2139,2197,3493,3808,416,587,886,1331,1529,1660,1716,1538,2281,2783,3210,\n",
    "                      3405,3772,4031,3689,4343,3405]\n",
    "    ifsamevideo[0] = [1,0,1,1,0,1,1,0,1,1,1,1,1,1,0,0,1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0]\n",
    "    # happiness\n",
    "    apexframe[1]   = [142,2218,2476,1412,329,1114,1415,1480,2207,77,400,997,1148,1358,1604,1703,1886,2261,858,1584,2291,2344,\n",
    "                      3180,1771,2986,993,1137,1432,2774,115,2753,858,1094,1597,1875,848,1431,1658,1842,1957,2237,2697,3181,872,\n",
    "                      966,140,203,183,341,569,1102,1451,2203,368,423,2234,1184,1779,1938,200,179,347,859,1195,1582,1936,1438,\n",
    "                      1562,1166,2259,1691,3193,1616,2203,1054,2253,775,410,873,1590,2218,264,363,666,739,1105,1579,1764,2092,\n",
    "                      2465,2683,1726,2234,1671,2338,1015,373,582,1087,861,1868,423,1182,1490,1963,2242,861,1587,1762,2044,2357,\n",
    "                      2709,244,423,342,888,1197,1800,1882,1250,1390,1675,1790,1881,2239,613,1613,2707]\n",
    "    ifsamevideo[1] = [1,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,\n",
    "                      0,1,1,0,1,1,0,0,1,1,1,1,1,0,1,0,1,0,1,0,0,0,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,0,0,1,1,0,1,0,1,1,1,1,\n",
    "                      0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,0,1,0]\n",
    "    # disgust\n",
    "    apexframe[2]   = [703,559,1799,214,334,430,535,727,841,177,376,391,525,1571,1716,1840,316,912,335,530,732,925,1364,478,1003,\n",
    "                      1017,321,434,428,880,1207,1713,39,377,559,804,1061,1460,357,785,412,572,756,1107,1426,1582,789,66,106,1296]\n",
    "    ifsamevideo[2] = [1,0,1,0,1,1,1,1,0,0,0,1,1,1,1,1,0,1,0,1,1,1,0,0,1,0,0,1,0,1,1,1,0,1,1,1,1,0,0,1,0,1,1,1,1,1,0,0,0,0]\n",
    "\n",
    "    path[0] = 'data-all/anger/'      #  50  video clips\n",
    "    path[1] = 'data-all/happiness/'  #  128 video clips\n",
    "    path[2] = 'data-all/disgust/'    #  50  video clips\n",
    "    \n",
    "else:\n",
    "    # anger\n",
    "    apexframe[0]   = [1898, 3447, 1139, 1979, 933, 1694, 2197, 3808]\n",
    "    ifsamevideo[0] = [1, 1, 0, 1, 0, 0, 1, 1]\n",
    "    # happiness\n",
    "    apexframe[1]   = [142, 329, 400, 1703, 1886, 2291, 1842, 1957, 3239, 619, 423, 1054, 264, 423, 2239] \n",
    "    ifsamevideo[1] = [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "    # disgust\n",
    "    apexframe[2]   = [703, 559, 275, 335, 530, 732, 1003, 1013, 1024, 880, 39, 377, 1460, 1426, 1037, 106] \n",
    "    ifsamevideo[2] = [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "    path[0] = 'data/angry/'    # 8  video clips\n",
    "    path[1] = 'data/happy/'    # 15 video clips\n",
    "    path[2] = 'data/disgust/'  # 16 video clips\n",
    "\n",
    "cascade_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 資料存檔/ 載入路徑\n",
    "if process_detect:\n",
    "    if version: imagefile = 'images_detect_new.npy'\n",
    "    else: imagefile       = 'images_detect_old.npy'\n",
    "else:\n",
    "    if version: imagefile = 'images_new.npy'\n",
    "    else: imagefile       = 'images_old.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37_0402beatingpregnantwoman.avi           left  524  apex  572  right  620\n",
      "27_0402beatingpregnantwoman.avi           left 2115  apex 2163  right 2211\n",
      "27_0402beatingpregnantwoman.avi           left 3323  apex 3371  right 3419\n",
      "27_0402beatingpregnantwoman.avi           left 3709  apex 3757  right 3805\n",
      "24_0402beatingpregnantwoman.avi           left  521  apex  569  right  617\n",
      "24_0402beatingpregnantwoman.avi           left 1627  apex 1675  right 1723\n",
      "24_0402beatingpregnantwoman.avi           left 1710  apex 1758  right 1806\n",
      "16_0401girlcrashing.avi                   left  373  apex  421  right  469\n",
      "16_0401girlcrashing.avi                   left 1343  apex 1391  right 1439\n",
      "16_0401girlcrashing.avi                   left 1833  apex 1881  right 1929\n",
      "16_0401girlcrashing.avi                   left 2114  apex 2162  right 2210\n",
      "16_0401girlcrashing.avi                   left 2864  apex 2912  right 2960\n",
      "16_0401girlcrashing.avi                   left 3373  apex 3421  right 3469\n",
      "16_0401girlcrashing.avi                   left 3615  apex 3943  right 3711\n",
      "27_0401girlcrashing.avi                   left 3222  apex 3270  right 3318\n",
      "31_0402beatingpregnantwoman.avi           left 1850  apex 1898  right 1946\n",
      "31_0402beatingpregnantwoman.avi           left 3399  apex 3447  right 3495\n",
      "32_0402beatingpregnantwoman.avi           left 3261  apex 3309  right 3357\n",
      "32_0402beatingpregnantwoman.avi           left 3515  apex 3563  right 3611\n",
      "15_0401girlcrashing.avi                   left 1091  apex 1139  right 1187\n",
      "15_0401girlcrashing.avi                   left 1931  apex 1979  right 2027\n",
      "15_0401girlcrashing.avi                   left 2120  apex 2168  right 2216\n",
      "15_0401girlcrashing.avi                   left 2199  apex 2247  right 2295\n",
      "32_0401girlcrashing.avi                   left 2593  apex 2641  right 2689\n",
      "32_0401girlcrashing.avi                   left 3621  apex 3733  right 3717\n",
      "16_0402beatingpregnantwoman.avi           left  367  apex  415  right  463\n",
      "16_0402beatingpregnantwoman.avi           left  885  apex  933  right  981\n",
      "30_0401girlcrashing.avi                   left  822  apex  870  right  918\n",
      "30_0401girlcrashing.avi                   left 1646  apex 1694  right 1742\n",
      "30_0401girlcrashing.avi                   left 2091  apex 2139  right 2187\n",
      "30_0401girlcrashing.avi                   left 2149  apex 2197  right 2245\n",
      "30_0401girlcrashing.avi                   left 3445  apex 3493  right 3541\n",
      "30_0401girlcrashing.avi                   left 3620  apex 3808  right 3716\n",
      "22_0402beatingpregnantwoman.avi           left  368  apex  416  right  464\n",
      "22_0402beatingpregnantwoman.avi           left  539  apex  587  right  635\n",
      "22_0402beatingpregnantwoman.avi           left  838  apex  886  right  934\n",
      "22_0402beatingpregnantwoman.avi           left 1283  apex 1331  right 1379\n",
      "22_0402beatingpregnantwoman.avi           left 1481  apex 1529  right 1577\n",
      "22_0402beatingpregnantwoman.avi           left 1612  apex 1660  right 1708\n",
      "22_0402beatingpregnantwoman.avi           left 1668  apex 1716  right 1764\n",
      "33_0402beatingpregnantwoman.avi           left 1490  apex 1538  right 1586\n",
      "33_0402beatingpregnantwoman.avi           left 2233  apex 2281  right 2329\n",
      "33_0402beatingpregnantwoman.avi           left 2735  apex 2783  right 2831\n",
      "33_0402beatingpregnantwoman.avi           left 3162  apex 3210  right 3258\n",
      "33_0402beatingpregnantwoman.avi           left 3357  apex 3405  right 3453\n",
      "33_0402beatingpregnantwoman.avi           left 3724  apex 3772  right 3820\n",
      "33_0402beatingpregnantwoman.avi           left 3983  apex 4031  right 4079\n",
      "15_0402beatingpregnantwoman.avi           left 3641  apex 3689  right 3737\n",
      "15_0402beatingpregnantwoman.avi           left 4274  apex 4343  right 4370\n",
      "24_0401girlcrashing.avi                   left 3357  apex 3405  right 3453\n",
      "25_0502funnyerrors.avi                    left   94  apex  142  right  190\n",
      "25_0502funnyerrors.avi                    left 2170  apex 2218  right 2266\n",
      "22_0503unnyfarting.avi                    left 2428  apex 2476  right 2524\n",
      "37_0507climbingthewall.avi                left 1364  apex 1412  right 1460\n",
      "31_0502funnyerrors.avi                    left  281  apex  329  right  377\n",
      "31_0502funnyerrors.avi                    left 1066  apex 1114  right 1162\n",
      "31_0502funnyerrors.avi                    left 1367  apex 1415  right 1463\n",
      "31_0502funnyerrors.avi                    left 1432  apex 1480  right 1528\n",
      "31_0502funnyerrors.avi                    left 2159  apex 2207  right 2255\n",
      "31_0507climbingthewall.avi                left   29  apex   77  right  125\n",
      "31_0507climbingthewall.avi                left  352  apex  400  right  448\n",
      "31_0507climbingthewall.avi                left  949  apex  997  right 1045\n",
      "31_0507climbingthewall.avi                left 1100  apex 1148  right 1196\n",
      "31_0507climbingthewall.avi                left 1310  apex 1358  right 1406\n",
      "31_0507climbingthewall.avi                left 1556  apex 1604  right 1652\n",
      "31_0507climbingthewall.avi                left 1655  apex 1703  right 1751\n",
      "31_0507climbingthewall.avi                left 1838  apex 1886  right 1934\n",
      "31_0507climbingthewall.avi                left 2213  apex 2261  right 2309\n",
      "22_0508funnydunkey.avi                    left  563  apex  858  right  659\n",
      "22_0508funnydunkey.avi                    left  563  apex 1584  right  659\n",
      "22_0508funnydunkey.avi                    left  563  apex 2291  right  659\n",
      "22_0508funnydunkey.avi                    left  563  apex 2344  right  659\n",
      "22_0508funnydunkey.avi                    left  563  apex 3180  right  659\n",
      "30_0503unnyfarting.avi                    left 1723  apex 1771  right 1819\n",
      "30_0502funnyerrors.avi                    left 2178  apex 2986  right 2274\n",
      "30_0505funnyinnovations.avi               left  945  apex  993  right 1041\n",
      "30_0505funnyinnovations.avi               left 1089  apex 1137  right 1185\n",
      "30_0505funnyinnovations.avi               left 1384  apex 1432  right 1480\n",
      "15_0502funnyerrors.avi                    left 2177  apex 2774  right 2273\n",
      "23_0507climbingthewall.avi                left   67  apex  115  right  163\n",
      "37_0505funnyinnovations.avi               left 2210  apex 2753  right 2306\n",
      "27_0503unnyfarting.avi                    left  810  apex  858  right  906\n",
      "27_0503unnyfarting.avi                    left 1046  apex 1094  right 1142\n",
      "27_0503unnyfarting.avi                    left 1549  apex 1597  right 1645\n",
      "27_0503unnyfarting.avi                    left 1827  apex 1875  right 1923\n",
      "16_0505funnyinnovations.avi               left  800  apex  848  right  896\n",
      "16_0505funnyinnovations.avi               left 1383  apex 1431  right 1479\n",
      "16_0505funnyinnovations.avi               left 1610  apex 1658  right 1706\n",
      "16_0505funnyinnovations.avi               left 1794  apex 1842  right 1890\n",
      "16_0505funnyinnovations.avi               left 1909  apex 1957  right 2005\n",
      "16_0505funnyinnovations.avi               left 2189  apex 2237  right 2285\n",
      "16_0505funnyinnovations.avi               left 2207  apex 2697  right 2303\n",
      "16_0505funnyinnovations.avi               left 2207  apex 3181  right 2303\n",
      "25_0508funnydunkey.avi                    left  564  apex  872  right  660\n",
      "25_0508funnydunkey.avi                    left  564  apex  966  right  660\n",
      "20_0502funnyerrors.avi                    left   92  apex  140  right  188\n",
      "20_0502funnyerrors.avi                    left  155  apex  203  right  251\n",
      "16_0502funnyerrors.avi                    left  135  apex  183  right  231\n",
      "16_0502funnyerrors.avi                    left  293  apex  341  right  389\n",
      "16_0502funnyerrors.avi                    left  521  apex  569  right  617\n",
      "16_0502funnyerrors.avi                    left 1054  apex 1102  right 1150\n",
      "16_0502funnyerrors.avi                    left 1403  apex 1451  right 1499\n",
      "16_0502funnyerrors.avi                    left 2155  apex 2203  right 2251\n",
      "32_0505funnyinnovations.avi               left  320  apex  368  right  416\n",
      "32_0505funnyinnovations.avi               left  375  apex  423  right  471\n",
      "32_0505funnyinnovations.avi               left 2186  apex 2234  right 2282\n",
      "32_0503unnyfarting.avi                    left 1136  apex 1184  right 1232\n",
      "32_0503unnyfarting.avi                    left 1731  apex 1779  right 1827\n",
      "32_0503unnyfarting.avi                    left 1890  apex 1938  right 1986\n",
      "40_0503unnyfarting.avi                    left  152  apex  200  right  248\n",
      "31_0505funnyinnovations.avi               left  131  apex  179  right  227\n",
      "31_0505funnyinnovations.avi               left  299  apex  347  right  395\n",
      "31_0505funnyinnovations.avi               left  811  apex  859  right  907\n",
      "31_0505funnyinnovations.avi               left 1147  apex 1195  right 1243\n",
      "31_0505funnyinnovations.avi               left 1534  apex 1582  right 1630\n",
      "31_0505funnyinnovations.avi               left 1888  apex 1936  right 1984\n",
      "27_0505funnyinnovations.avi               left 1390  apex 1438  right 1486\n",
      "27_0505funnyinnovations.avi               left 1514  apex 1562  right 1610\n",
      "27_0508funnydunkey.avi                    left  564  apex 1166  right  660\n",
      "27_0508funnydunkey.avi                    left  564  apex 2259  right  660\n",
      "36_0505funnyinnovations.avi               left 1643  apex 1691  right 1739\n",
      "36_0505funnyinnovations.avi               left 2210  apex 3193  right 2306\n",
      "19_0505funnyinnovations.avi               left 1568  apex 1616  right 1664\n",
      "15_0505funnyinnovations.avi               left 2155  apex 2203  right 2251\n",
      "38_0502funnyerrors.avi                    left 1006  apex 1054  right 1102\n",
      "38_0502funnyerrors.avi                    left 2181  apex 2253  right 2277\n",
      "31_0503unnyfarting.avi                    left  727  apex  775  right  823\n",
      "15_0503unnyfarting.avi                    left  362  apex  410  right  458\n",
      "15_0503unnyfarting.avi                    left  825  apex  873  right  921\n",
      "15_0503unnyfarting.avi                    left 1542  apex 1590  right 1638\n",
      "15_0503unnyfarting.avi                    left 2170  apex 2218  right 2266\n",
      "37_0502funnyerrors.avi                    left  216  apex  264  right  312\n",
      "37_0502funnyerrors.avi                    left  315  apex  363  right  411\n",
      "37_0502funnyerrors.avi                    left  618  apex  666  right  714\n",
      "37_0502funnyerrors.avi                    left  691  apex  739  right  787\n",
      "37_0502funnyerrors.avi                    left 1057  apex 1105  right 1153\n",
      "37_0502funnyerrors.avi                    left 1531  apex 1579  right 1627\n",
      "37_0502funnyerrors.avi                    left 1716  apex 1764  right 1812\n",
      "37_0502funnyerrors.avi                    left 2044  apex 2092  right 2140\n",
      "37_0502funnyerrors.avi                    left 2174  apex 2465  right 2270\n",
      "37_0502funnyerrors.avi                    left 2174  apex 2683  right 2270\n",
      "38_0507climbingthewall.avi                left 1678  apex 1726  right 1774\n",
      "38_0507climbingthewall.avi                left 2186  apex 2234  right 2282\n",
      "37_0508funnydunkey.avi                    left  564  apex 1671  right  660\n",
      "37_0508funnydunkey.avi                    left  564  apex 2338  right  660\n",
      "27_0502funnyerrors.avi                    left  967  apex 1015  right 1063\n",
      "19_0507climbingthewall.avi                left  325  apex  373  right  421\n",
      "19_0507climbingthewall.avi                left  534  apex  582  right  630\n",
      "19_0507climbingthewall.avi                left 1039  apex 1087  right 1135\n",
      "24_0507climbingthewall.avi                left  813  apex  861  right  909\n",
      "24_0507climbingthewall.avi                left 1820  apex 1868  right 1916\n",
      "32_0507climbingthewall.avi                left  375  apex  423  right  471\n",
      "32_0507climbingthewall.avi                left 1134  apex 1182  right 1230\n",
      "32_0507climbingthewall.avi                left 1442  apex 1490  right 1538\n",
      "32_0507climbingthewall.avi                left 1915  apex 1963  right 2011\n",
      "32_0507climbingthewall.avi                left 2194  apex 2242  right 2290\n",
      "40_0502funnyerrors.avi                    left  813  apex  861  right  909\n",
      "40_0502funnyerrors.avi                    left 1539  apex 1587  right 1635\n",
      "40_0502funnyerrors.avi                    left 1714  apex 1762  right 1810\n",
      "40_0502funnyerrors.avi                    left 1996  apex 2044  right 2092\n",
      "40_0502funnyerrors.avi                    left 2179  apex 2357  right 2275\n",
      "40_0502funnyerrors.avi                    left 2179  apex 2709  right 2275\n",
      "34_0503unnyfarting.avi                    left  196  apex  244  right  292\n",
      "34_0503unnyfarting.avi                    left  375  apex  423  right  471\n",
      "24_0502funnyerrors.avi                    left  294  apex  342  right  390\n",
      "24_0502funnyerrors.avi                    left  840  apex  888  right  936\n",
      "24_0502funnyerrors.avi                    left 1149  apex 1197  right 1245\n",
      "24_0502funnyerrors.avi                    left 1752  apex 1800  right 1848\n",
      "24_0502funnyerrors.avi                    left 1834  apex 1882  right 1930\n",
      "32_0502funnyerrors.avi                    left 1202  apex 1250  right 1298\n",
      "32_0502funnyerrors.avi                    left 1342  apex 1390  right 1438\n",
      "32_0502funnyerrors.avi                    left 1627  apex 1675  right 1723\n",
      "32_0502funnyerrors.avi                    left 1742  apex 1790  right 1838\n",
      "32_0502funnyerrors.avi                    left 1833  apex 1881  right 1929\n",
      "32_0502funnyerrors.avi                    left 2178  apex 2239  right 2274\n",
      "16_0507climbingthewall.avi                left  565  apex  613  right  661\n",
      "16_0507climbingthewall.avi                left 1565  apex 1613  right 1661\n",
      "30_0507climbingthewall.avi                left 2659  apex 2707  right 2755\n",
      "26_0102eatingworms.avi                    left  655  apex  703  right  751\n",
      "22_0102eatingworms.avi                    left  511  apex  559  right  607\n",
      "22_0102eatingworms.avi                    left  976  apex 1799  right 1072\n",
      "33_0102eatingworms.avi                    left  166  apex  214  right  262\n",
      "33_0102eatingworms.avi                    left  286  apex  334  right  382\n",
      "33_0102eatingworms.avi                    left  382  apex  430  right  478\n",
      "33_0102eatingworms.avi                    left  487  apex  535  right  583\n",
      "33_0102eatingworms.avi                    left  679  apex  727  right  775\n",
      "27_0101disgustingteeth.avi                left  793  apex  841  right  889\n",
      "16_0102eatingworms.avi                    left  129  apex  177  right  225\n",
      "24_0101disgustingteeth.avi                left  328  apex  376  right  424\n",
      "24_0101disgustingteeth.avi                left  343  apex  391  right  439\n",
      "24_0101disgustingteeth.avi                left  477  apex  525  right  573\n",
      "24_0101disgustingteeth.avi                left 1523  apex 1571  right 1619\n",
      "24_0101disgustingteeth.avi                left 1668  apex 1716  right 1764\n",
      "24_0101disgustingteeth.avi                left 1792  apex 1840  right 1888\n",
      "35_0102eatingworms.avi                    left  268  apex  316  right  364\n",
      "35_0102eatingworms.avi                    left  864  apex  912  right  960\n",
      "37_0101disgustingteeth.avi                left  287  apex  335  right  383\n",
      "37_0101disgustingteeth.avi                left  482  apex  530  right  578\n",
      "37_0101disgustingteeth.avi                left  684  apex  732  right  780\n",
      "37_0101disgustingteeth.avi                left  877  apex  925  right  973\n",
      "32_0102eatingworms.avi                    left  975  apex 1364  right 1071\n",
      "15_0102eatingworms.avi                    left  430  apex  478  right  526\n",
      "15_0102eatingworms.avi                    left  955  apex 1003  right 1051\n",
      "26_0101disgustingteeth.avi                left  969  apex 1017  right 1065\n",
      "22_0101disgustingteeth.avi                left  273  apex  321  right  369\n",
      "22_0101disgustingteeth.avi                left  386  apex  434  right  482\n",
      "30_0102eatingworms.avi                    left  380  apex  428  right  476\n",
      "30_0102eatingworms.avi                    left  832  apex  880  right  928\n",
      "30_0102eatingworms.avi                    left  973  apex 1207  right 1069\n",
      "30_0102eatingworms.avi                    left  973  apex 1713  right 1069\n",
      "25_0102eatingworms.avi                    left    0  apex   39  right   96\n",
      "25_0102eatingworms.avi                    left  329  apex  377  right  425\n",
      "25_0102eatingworms.avi                    left  511  apex  559  right  607\n",
      "25_0102eatingworms.avi                    left  756  apex  804  right  852\n",
      "25_0102eatingworms.avi                    left  979  apex 1061  right 1075\n",
      "30_0101disgustingteeth.avi                left 1412  apex 1460  right 1508\n",
      "31_0101disgustingteeth.avi                left  309  apex  357  right  405\n",
      "31_0101disgustingteeth.avi                left  737  apex  785  right  833\n",
      "23_0102eatingworms.avi                    left  364  apex  412  right  460\n",
      "23_0102eatingworms.avi                    left  524  apex  572  right  620\n",
      "23_0102eatingworms.avi                    left  708  apex  756  right  804\n",
      "23_0102eatingworms.avi                    left  975  apex 1107  right 1071\n",
      "23_0102eatingworms.avi                    left  975  apex 1426  right 1071\n",
      "23_0102eatingworms.avi                    left  975  apex 1582  right 1071\n",
      "27_0102eatingworms.avi                    left  741  apex  789  right  837\n",
      "16_0101disgustingteeth.avi                left   18  apex   66  right  114\n",
      "19_0102eatingworms.avi                    left   58  apex  106  right  154\n",
      "21_0101disgustingteeth.avi                left 1248  apex 1296  right 1344\n"
     ]
    }
   ],
   "source": [
    "def video_clips(detect):\n",
    "    for v in range(num_classes):\n",
    "        k = 0 # index of directorylisting\n",
    "        directorylisting = os.listdir(path[v])\n",
    "        for i in range(len(apexframe[v])):\n",
    "            if ifsamevideo[v][i] == False: # 目前短片與上一個短片來自不同影片，index k++\n",
    "                k = k + 1\n",
    "            video = directorylisting[k]\n",
    "            videopath = path[v] + video\n",
    "            loadedvideo = imageio.get_reader(videopath, 'ffmpeg')\n",
    "            length = loadedvideo.count_frames() # 影片最大幀數\n",
    "\n",
    "            # 邊界處理\n",
    "            apex = apexframe[v][i]\n",
    "            left  = apex - look_frames # 左 偏移量\n",
    "            right = apex + look_frames # 右 偏移量\n",
    "            if right > length:\n",
    "                right = length\n",
    "                left  = right - image_depth\n",
    "            elif left < 0:\n",
    "                left  = 0\n",
    "                right = left + image_depth\n",
    "            print(\"{:40}  left{:5}  apex{:5}  right{:5}\". format(video, left, apex, right))\n",
    "\n",
    "            # 沒有對資料做 detect 一樣的處理\n",
    "            if detect == False:\n",
    "                frames = [] \n",
    "                framerange = [x for x in range(left, right)] # 取apex frame的前後幾幀     \n",
    "                for frame in framerange:\n",
    "                    image = loadedvideo.get_data(frame)\n",
    "                    imageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
    "                    grayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
    "                    frames.append(grayimage)\n",
    "                \"\"\"\n",
    "                # 印出apex前後共15幀\n",
    "                count = 0\n",
    "                framerange = [apex + i for i in range(-7, 8)] \n",
    "                plt.figure(figsize=(15, 2))\n",
    "                for frame in framerange:\n",
    "                    count += 1\n",
    "                    image = loadedvideo.get_data(frame)\n",
    "                    imageresize = cv2.resize(image, (image_rows, image_columns), interpolation=cv2.INTER_AREA)\n",
    "                    plt.subplot(1, 15, count)\n",
    "                    plt.imshow(imageresize)\n",
    "                    plt.axis('off') # 關閉刻度\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                \n",
    "                frames = np.asarray(frames)\n",
    "                videoarray = np.rollaxis(np.rollaxis(frames, 2, 0), 2, 0)\n",
    "                training_list.append(videoarray)\n",
    "\n",
    "\n",
    "            #對資料做 detect 一樣的處理    \n",
    "            elif detect == True: \n",
    "                frames = [] \n",
    "                framerange = [x for x in range(left, right)] # 取apex frame的前後幀\n",
    "                frame_count = 0 # 紀錄每個輸入影片的幀數\n",
    "                for frame in framerange: # 將資料改為跟Detect一樣\n",
    "                    image = loadedvideo.get_data(frame)\n",
    "                    grayimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                    face_rects = cascade_classifier.detectMultiScale(grayimage, 1.2, 6) # 人臉偵測\n",
    "                    for (x,y,w,h) in face_rects: # 偵測的框架\n",
    "                        gray_roi = grayimage[y:y+h, x:x+w] # 框架區域\n",
    "                        imageresize = cv2.resize(gray_roi, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
    "                        frames.append(imageresize)\n",
    "                        last_frame = imageresize # 紀錄最後一幀\n",
    "                        frame_count += 1\n",
    "\n",
    "                for a in range(frame_count, image_depth): # 不足96幀數的影片，都用最後一幀補滿\n",
    "                    frames.append(last_frame)\n",
    "\n",
    "                frames = np.asarray(frames)\n",
    "                videoarray = np.rollaxis(np.rollaxis(frames, 2, 0), 2, 0)\n",
    "                training_list.append(videoarray)\n",
    "                print(\"video\", i+1, np.asarray(videoarray).shape)\n",
    "\n",
    "                plt.figure(figsize=(1, 1))\n",
    "                plt.imshow(last_frame)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "video_clips(process_detect)  \n",
    "np.save(imagefile, training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "128\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for i in apexframe:\n",
    "    print(len(i))\n",
    "    \n",
    "training_list = np.load(imagefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 1, 64, 64, 96)\n"
     ]
    }
   ],
   "source": [
    "training_list = np.asarray(training_list)\n",
    "trainingsamples = len(training_list)\n",
    "\n",
    "# 設定label\n",
    "traininglabels = np.zeros((trainingsamples, ), dtype = int) \n",
    "if version:\n",
    "    traininglabels[0:50] = 0     # 50  video clips (anger)\n",
    "    traininglabels[50:178] = 1   # 128 video clips (happiness)\n",
    "    traininglabels[178:228] = 2  # 50  video clips (disgust)\n",
    "else:\n",
    "    traininglabels[0:8] = 0      #  8  video clips (anger)\n",
    "    traininglabels[8:23] = 1     # 15  video clips (happiness)\n",
    "    traininglabels[23:39] = 2    # 16  video clips (disgust)\n",
    "traininglabels = np_utils.to_categorical(traininglabels, num_classes) # one-hot編碼\n",
    "\n",
    "# 資料轉為五維\n",
    "training_set = np.zeros((trainingsamples, 1, image_rows, image_columns, image_depth))\n",
    "for h in range(trainingsamples):\n",
    "    training_set[h][0][:][:][:] = training_list[h,:,:,:]\n",
    "print(training_set.shape)\n",
    "\n",
    "# 資料處理 標準化\n",
    "training_set = training_set.astype('float32')\n",
    "training_set -= np.mean(training_set) # 消除數據的偏差 (與其他資料集相比)\n",
    "training_set /= np.max(training_set)  # 使數據介於0~1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 32, 62, 62, 82)    4352      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 32, 20, 20, 27)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 20, 20, 27)    0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 345600)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               44236928  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,241,667\n",
      "Trainable params: 44,241,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 15:43:02.998960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-28 15:43:02.999118: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:43:02.999148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:43:02.999172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:43:02.999194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:43:03.016189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:43:03.016237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/infor/miniconda3/envs/torch/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-05-28 15:43:03.016243: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-28 15:43:03.016635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def CNN_3D():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution3D(32, (3, 3, 15), input_shape=(1, image_rows, image_columns, image_depth), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "CNN_3D().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, epochs, batch_size=32):\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    102\n",
      "0     40\n",
      "2     40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 資料切割\n",
    "train_images, validation_images, train_labels, validation_labels = train_test_split(\n",
    "        training_set, traininglabels, test_size=0.2, random_state=4, stratify=traininglabels)\n",
    "\n",
    "# 資料分布\n",
    "train_labels_int = np.argmax(train_labels, axis=1)\n",
    "label_series = pd.Series(train_labels_int)\n",
    "class_distribution = label_series.value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(models):\n",
    "    model_weights = [model.get_weights() for model in models]\n",
    "    avg_weights = list()\n",
    "    for weights_list_tuple in zip(*model_weights):\n",
    "        avg_weights.append(\n",
    "            np.array([np.array(weights_).mean(axis=0) for weights_ in zip(*weights_list_tuple)]))\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 2 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 3 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 4 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 5 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 6 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 7 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 8 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 9 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "Round 10 of 10\n",
      "Training client 1 of 5\n",
      "Training client 2 of 5\n",
      "Training client 3 of 5\n",
      "Training client 4 of 5\n",
      "Training client 5 of 5\n",
      "2/2 [==============================] - 1s 241ms/step - loss: 0.8901 - accuracy: 0.6087\n",
      "Global model validation accuracy: 0.6086956262588501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"model = CNN_3D()\\nmodelcheckpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\\ntrain(model, train_images, train_labels, epochs=50, batch_size=32)\\n\\n# 評估模型\\nloss, acc = model.evaluate(validation_images, validation_labels)\\nprint('Validation loss:', loss)\\nprint('Validation accuracy:', acc)\\n\\n# 預測\\npredicted = model.predict(validation_images)\\npredicted = np.argmax(predicted, axis=1)\\nvalidation_labels = np.argmax(validation_labels, axis=1)\\ncm = confusion_matrix(validation_labels, predicted)\\nprint(cm)\\n\\n# 繪製混淆矩陣\\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\\nplt.xlabel('Predicted')\\nplt.ylabel('True')\\nplt.show()\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main federated learning training loop\n",
    "NUM_CLIENTS = 5\n",
    "NUM_ROUNDS = 10\n",
    "epochs = 5\n",
    "\n",
    "# Initialize models for each client\n",
    "models = [CNN_3D() for _ in range(NUM_CLIENTS)]\n",
    "\n",
    "# Split training data among clients\n",
    "train_images_split = np.array_split(train_images, NUM_CLIENTS)\n",
    "train_labels_split = np.array_split(train_labels, NUM_CLIENTS)\n",
    "\n",
    "# Train models on client data\n",
    "\n",
    "for i in range(NUM_ROUNDS):\n",
    "    print(f\"Round {i+1} of {NUM_ROUNDS}\")\n",
    "    for j in range(NUM_CLIENTS):\n",
    "        print(f\"Training client {j+1} of {NUM_CLIENTS}\")\n",
    "        train(models[j], train_images_split[j], train_labels_split[j], epochs=epochs)\n",
    "    # Update global model\n",
    "    avg_weights = fed_avg(models)\n",
    "    for model in models:\n",
    "        model.set_weights(avg_weights)\n",
    "\n",
    "# Evaluate global model\n",
    "global_model = CNN_3D()\n",
    "global_model.set_weights(avg_weights)\n",
    "loss, acc = global_model.evaluate(validation_images, validation_labels)\n",
    "print(f\"Global model validation accuracy: {acc}\")\n",
    "\n",
    "# 訓練模型\n",
    "\"\"\"model = CNN_3D()\n",
    "modelcheckpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "train(model, train_images, train_labels, epochs=50, batch_size=32)\n",
    "\n",
    "# 評估模型\n",
    "loss, acc = model.evaluate(validation_images, validation_labels)\n",
    "print('Validation loss:', loss)\n",
    "print('Validation accuracy:', acc)\n",
    "\n",
    "# 預測\n",
    "predicted = model.predict(validation_images)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "validation_labels = np.argmax(validation_labels, axis=1)\n",
    "cm = confusion_matrix(validation_labels, predicted)\n",
    "print(cm)\n",
    "\n",
    "# 繪製混淆矩陣\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
